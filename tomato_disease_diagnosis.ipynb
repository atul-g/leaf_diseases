{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tomato_disease_diagnosis",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg6yNSmmGTDl",
        "colab_type": "text"
      },
      "source": [
        "###Connecting to Drive where the dataset is stored:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8pCUermHpS",
        "colab_type": "code",
        "outputId": "376ebe8a-3f0e-43ab-a29b-53612e78cc71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zTyVNjZGc42",
        "colab_type": "text"
      },
      "source": [
        "###Use this snippet to separate the files in the dataset into train and test folders:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrD8WhuzJCS0",
        "colab_type": "code",
        "outputId": "cfc81620-92a6-4626-c13f-23b114dfb491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "#for moving the files into respective test and train directory\n",
        "#before this use the file_rename.sh shell script to rename all files in\n",
        "#proper numerical order.\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "cwd=os.path.join(os.getcwd(), 'drive/My Drive')\n",
        "os.mkdir(os.path.join(cwd,'train'))\n",
        "os.mkdir(os.path.join(cwd,'test'))\n",
        "for dir in os.listdir(cwd+'/tomato_disease_dataset'):\n",
        "\tfile_list=os.listdir(os.path.join(cwd,'tomato_disease_dataset', dir))\n",
        "\tln=len(file_list)\n",
        "\ttrain=file_list[:int(ln*0.8)]\n",
        "\ttest=[x for x in file_list if x not in train]\n",
        "\t\n",
        "\t#moving train files:\n",
        "\tos.mkdir(os.path.join(cwd,'train', dir))\n",
        "\tfor f in train:\n",
        "\t\tshutil.move(os.path.join(cwd,'tomato_disease_dataset', dir, f),os.path.join(cwd, 'train', dir, f))\n",
        "\t\t\n",
        "\t#moving test files:\n",
        "\tos.mkdir(os.path.join(cwd,'test', dir))\n",
        "\tfor f in test:\n",
        "\t\tshutil.move(os.path.join(cwd,'tomato_disease_dataset', dir, f),os.path.join(cwd, 'test', dir, f))\n",
        "\t\n",
        "\t\n",
        "print(\"\\nDone moving files\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done moving files\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1S0Ypf0GrxU",
        "colab_type": "text"
      },
      "source": [
        "###Importing tensorflow and required libraries and also implementing Image Augmentation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtO8REAuk5WH",
        "colab_type": "code",
        "outputId": "85629c2f-132b-476f-c512-50db59679152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##### CREATING TEST AND TRAIN IMAGE DATA GENERATORS\n",
        "IMG_SIZE=256\n",
        "\n",
        "import os\n",
        "cwd=os.path.join(os.getcwd(), 'drive/My Drive')\n",
        "\n",
        "image_gen_train = ImageDataGenerator(rescale=1./255, horizontal_flip=True, rotation_range=60, width_shift_range=0.2, height_shift_range=0.2, zoom_range=0.2, fill_mode='nearest')\n",
        "\n",
        "train_gen = image_gen_train.flow_from_directory(batch_size=32, directory = cwd+'/train', shuffle = True, target_size =(IMG_SIZE, IMG_SIZE), class_mode = 'sparse')\n",
        "\n",
        "image_gen_test = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_gen = image_gen_test.flow_from_directory(batch_size=32, directory=cwd+'/test', target_size=(IMG_SIZE, IMG_SIZE), class_mode='sparse')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13324 images belonging to 10 classes.\n",
            "Found 3337 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1Q_Yf0pG2oE",
        "colab_type": "text"
      },
      "source": [
        "###Creating the model. Getting pre-trained models using Tensorflow Hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTdYz4EOy0-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "'''\n",
        "imagenet - (192,192) : https://tfhub.dev/google/imagenet/mobilenet_v1_075_192/quantops/feature_vector/3\n",
        "inception-resnet-v2 - (299, 299) or closer: https://tfhub.dev/google/imagenet/inception_resnet_v2/classification/4\n",
        "'''\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v1_075_192/quantops/feature_vector/3\", trainable=False, input_shape=(192,192,3)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaZcpYdkHC9q",
        "colab_type": "text"
      },
      "source": [
        "###Training the model and also plotting the losses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrHVpPnR1lCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit_generator(train_gen,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=test_gen)\n",
        "\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "model.save(cwd+'/my_tomato_model_mobilenet.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YqZTD3QR0i",
        "colab_type": "text"
      },
      "source": [
        "###Testing the model manually on few random Tomato leaf pictures:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvB0uy45HNYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "cd4f1cd8-0fcf-41b3-a6ad-027cba960fe6"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "model=load_model(\"/content/drive/My Drive/my_tomato_model_imagenet.h5\", custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "\n",
        "dir=\"/content/drive/My Drive/model_testing/\"\n",
        "img_list=[]\n",
        "for i in os.listdir(dir):\n",
        "    img=image.load_img(dir+i, target_size=(192, 192))\n",
        "    img=image.img_to_array(img)\n",
        "    img=np.expand_dims(img, axis=0)\n",
        "    img_list.append(img)\n",
        "\n",
        "img_list=np.vstack(img_list)\n",
        "\n",
        "classes = model.predict(img_list, batch_size=10)\n",
        "for i in classes:\n",
        "  print(f\"Class:{i.argmax()+1}, Accuracy:{i.max()}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class:5, Accuracy:0.9393425583839417\n",
            "Class:5, Accuracy:0.954954206943512\n",
            "Class:5, Accuracy:0.9573853015899658\n",
            "Class:5, Accuracy:0.7382345199584961\n",
            "Class:3, Accuracy:0.9953210949897766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjMoAguqATg_",
        "colab_type": "text"
      },
      "source": [
        "# Using VGG16 from keras applications:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUH4Zvb1ivyJ",
        "colab_type": "code",
        "outputId": "a0b2758d-014a-4ae4-f798-160101682688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "\n",
        "base_model=VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# First: train only the top layers (which were randomly initialized)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                327690    \n",
            "=================================================================\n",
            "Total params: 15,042,378\n",
            "Trainable params: 327,690\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwlLQklBow-",
        "colab_type": "code",
        "outputId": "5c2657b2-0d40-48e1-9741-e8fffdcbd20d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training the model\n",
        "EPOCHS = 20\n",
        "history = model.fit_generator(train_gen,\n",
        "                    steps_per_epoch=416,         \n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=test_gen,\n",
        "                    validation_steps=104)\n",
        "model.save(cwd+'/my_tomato_model_vgg16.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6986 - acc: 0.8140Epoch 1/20\n",
            "416/416 [==============================] - 227s 546ms/step - loss: 0.6980 - acc: 0.8141 - val_loss: 0.6529 - val_acc: 0.8356\n",
            "Epoch 2/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6734 - acc: 0.8224Epoch 1/20\n",
            "416/416 [==============================] - 228s 547ms/step - loss: 0.6726 - acc: 0.8226 - val_loss: 0.5284 - val_acc: 0.8642\n",
            "Epoch 3/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6639 - acc: 0.8282Epoch 1/20\n",
            "416/416 [==============================] - 228s 549ms/step - loss: 0.6647 - acc: 0.8280 - val_loss: 0.6893 - val_acc: 0.8290\n",
            "Epoch 4/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6676 - acc: 0.8293Epoch 1/20\n",
            "416/416 [==============================] - 227s 546ms/step - loss: 0.6677 - acc: 0.8293 - val_loss: 0.9648 - val_acc: 0.8101\n",
            "Epoch 5/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.8339Epoch 1/20\n",
            "416/416 [==============================] - 225s 541ms/step - loss: 0.6573 - acc: 0.8337 - val_loss: 0.5034 - val_acc: 0.8654\n",
            "Epoch 6/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.7221 - acc: 0.8247Epoch 1/20\n",
            "416/416 [==============================] - 224s 538ms/step - loss: 0.7225 - acc: 0.8245 - val_loss: 0.5684 - val_acc: 0.8660\n",
            "Epoch 7/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.8378Epoch 1/20\n",
            "416/416 [==============================] - 223s 537ms/step - loss: 0.6460 - acc: 0.8377 - val_loss: 0.7856 - val_acc: 0.8477\n",
            "Epoch 8/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6424 - acc: 0.8422Epoch 1/20\n",
            "416/416 [==============================] - 221s 531ms/step - loss: 0.6426 - acc: 0.8422 - val_loss: 0.5654 - val_acc: 0.8735\n",
            "Epoch 9/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6931 - acc: 0.8349Epoch 1/20\n",
            "416/416 [==============================] - 220s 529ms/step - loss: 0.6917 - acc: 0.8352 - val_loss: 0.5531 - val_acc: 0.8627\n",
            "Epoch 10/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6577 - acc: 0.8398Epoch 1/20\n",
            "416/416 [==============================] - 217s 521ms/step - loss: 0.6568 - acc: 0.8400 - val_loss: 0.4837 - val_acc: 0.8765\n",
            "Epoch 11/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6792 - acc: 0.8379Epoch 1/20\n",
            "416/416 [==============================] - 220s 528ms/step - loss: 0.6795 - acc: 0.8379 - val_loss: 0.5413 - val_acc: 0.8726\n",
            "Epoch 12/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6580 - acc: 0.8416Epoch 1/20\n",
            "416/416 [==============================] - 218s 523ms/step - loss: 0.6581 - acc: 0.8416 - val_loss: 0.5387 - val_acc: 0.8669\n",
            "Epoch 13/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6416 - acc: 0.8431Epoch 1/20\n",
            "416/416 [==============================] - 220s 529ms/step - loss: 0.6422 - acc: 0.8432 - val_loss: 0.4817 - val_acc: 0.8837\n",
            "Epoch 14/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6721 - acc: 0.8403Epoch 1/20\n",
            "416/416 [==============================] - 220s 529ms/step - loss: 0.6717 - acc: 0.8404 - val_loss: 0.5981 - val_acc: 0.8684\n",
            "Epoch 15/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.8502Epoch 1/20\n",
            "416/416 [==============================] - 219s 525ms/step - loss: 0.6404 - acc: 0.8502 - val_loss: 0.4581 - val_acc: 0.8906\n",
            "Epoch 16/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6715 - acc: 0.8397Epoch 1/20\n",
            "416/416 [==============================] - 217s 521ms/step - loss: 0.6713 - acc: 0.8397 - val_loss: 0.6676 - val_acc: 0.8468\n",
            "Epoch 17/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.8497Epoch 1/20\n",
            "416/416 [==============================] - 216s 519ms/step - loss: 0.6335 - acc: 0.8492 - val_loss: 0.5056 - val_acc: 0.8783\n",
            "Epoch 18/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6772 - acc: 0.8463Epoch 1/20\n",
            "416/416 [==============================] - 218s 525ms/step - loss: 0.6761 - acc: 0.8465 - val_loss: 0.8690 - val_acc: 0.8323\n",
            "Epoch 19/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6865 - acc: 0.8483Epoch 1/20\n",
            "416/416 [==============================] - 217s 522ms/step - loss: 0.6860 - acc: 0.8484 - val_loss: 0.7218 - val_acc: 0.8528\n",
            "Epoch 20/20\n",
            "415/416 [============================>.] - ETA: 0s - loss: 0.6493 - acc: 0.8503Epoch 1/20\n",
            "416/416 [==============================] - 216s 519ms/step - loss: 0.6509 - acc: 0.8501 - val_loss: 0.5055 - val_acc: 0.8858\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}