1. file_rename.sh - a shell script to rename the files in a numerical order.

2. train_test_split.py was made to split the images in 80:20 ratio. the 
'train' and 'test' directory was created as a result of this right under the
root directory from the original 'tomato_disease_dataset' which was deleted after the 
execution of this script as it was no longer needed.

3. Inception-resnet-v2 model gave 87% validation accuracy after training for 10 epochs.
(took around 7 hours in colab). Batch Size was 64

4. trained it again with image augmentations for 7 epochs, got 85% accuracy. Model 
saved as my_tomato_model.h5 (size 214 mb!). Batch Size was 64

5. Trained with imagenet v2, got 88% accuracy for 64 batch size. size was only
7 MB!

6. Need to check Alexnet or VGGnet for batch size 64 and 32.

7. Trained resnet-v2-152, got 88% validation accuracy with 32% batch size. size 
of the trained model is 222mb. still preferring imagenet model.

8. Trained mobilenet with 0.0001 lr, got a val acc of 82% at 10 epochs.

10. used git lfs to push large files like inception-resnet trained models.
  for that, I had to first install git-lfs using apt. Then use git install lfs
  in the working directory.
  I then had to use a certain command: git lfs migrate import --include="my_tomato_model_inecption-resnet.h5"
  in order to push as normally pushing gave certain errors.
  
11. Trained vgg16 model for 10 epochs, got 86%val acc and only 81% acc. Gonna
train it for 20 epochs and see if any difference.

12. In order to upload the model to firebase, we have to first convert h5 model
to .pb graph - for this we used h5_to_pb.py script which I got from an answer
in stackoverflow.

13. Note: loading the trained model using keras.model.load_model yields some 
error, so I used the cutom_objects parameter while using the same function.


